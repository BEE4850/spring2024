---
title: "Markov Chain Monte Carlo"
subtitle: "Lecture 14"
author: "Vivek Srikrishnan"
course: "BEE 4850"
institution: "Cornell University"
date: "March 18, 2024"
format:
    revealjs:
        slide-number: c/t
        show-slide-number: all
        center-title-slide: true
        width: 1280
        height: 720
        transition: none
        toc: true
        toc-depth: 1
        toc-title: "Overview"
        history: false
        link-external-newwindow: true
        theme: ../sass/slides.scss
        template-partials:
            - title-slide.html
        menu:
            numbers: true
        html-math-method: 
            method: mathjax
            url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
        include-in-header: mathjax-config.html
        date-format: long
        email-obfuscation: javascript
        chalkboard:
            theme: whiteboard
            buttons: true
        touch: false
        controls: true
engine: julia
julia:
    exeflags: ["+1.10.4"]          
execute:
    freeze: auto
---

```{julia}
#| output: false

import Pkg
Pkg.activate(@__DIR__)
Pkg.instantiate()
```

```{julia}
#| output: false

using Random
using Distributions
using ColorSchemes
using Plots
using StatsPlots
using StatsBase
using LaTeXStrings
using Measures
using Loess
using QuadGK
using LinearAlgebra
using MCMCChains

Random.seed!(1)
```

# Last Class

## Bayesian Computation

- **Goal**: Sample from posterior distribution to:
  - Capture parametric uncertainty;
  - Compute MAP estimates.
- Challenging because of arbitrary nature of distributions.

## Markov Chain Strategy

- Generate an appropriate Markov chain so that its stationary distribution of the target distribution $\pi$;
- Run its dynamics long enough to converge to the stationary distribution;
- Use the resulting ensemble of states as Monte Carlo samples from $\pi$ .

## Markov Chain Convergence

Given a Markov chain $\{X_t\}_{t=1, \ldots, T}$ returned from this procedure, sampling from distribution $\pi$:

- $\mathbb{P}(X_t = y) \to \pi(y)$ as $t \to \infty$
- This means the chain can be considered a *dependent* sample approximately distributed from $\pi$.
- The first values (the *transient portion*) of the chain are highly dependent on the initial value.

# Metropolis-Hastings Algorithm

## The Metropolis-Hastings Algorithm

The **Metropolis-Hastings** algorithm:

- The foundational MCMC algorithm (and was named [one of the top ten algorithms of the 20th century](https://www.computer.org/csdl/magazine/cs/2000/01/c1022/13rRUxBJhBm)).
- Builds a Markov chain based on transitions by:
  - generating proposals for new samples from a *conditional proposal distribution* $q(y | x)$;
  - accepting or rejecting those proposals.

## The Metropolis-Hastings Algorithm

Given $X_t = x_t$:

1. Generate $Y_t \sim q(y | x_t)$;
2. Set $X_{t+1} = Y_t$ with probability $\rho(x_t, Y_t)$, where
    $$\rho(x, y) = \min \left\{\frac{\pi(y)}{\pi(x)}\frac{q(x | y)}{q(y | x)}, 1\right\},$$
    else set $X_{t+1} = x_t$.

## How Simple Is That?

The devil is in the details: performance and efficiency are highly dependent on the choice of $q$.

::: {.fragment .fade-in}
**Key**: There is a tradeoff between exploration and acceptance.

- Wide proposal: Can make bigger jumps, may be more likely to reject proposals.
- Narrow proposal: More likely to accept proposals, may not "mix" efficiently.
:::

## Proposal Distribution Choice

The original @Metropolis1953-rv algorithm used symmetric distributions ($q(y | x) = q(x | y)$).

Then the acceptance probability reduces to $$\rho =  \min \left\{\frac{\pi(y)}{\pi(x)}, 1\right\}.$$

**A common choice**: $y \sim \text{Normal}(X_t, \sigma)$ centered around the current point $X_t$.

## Julia Implementation

```{julia}
#| echo: true
#| label: mcmc-transition

function mh_transition(x_current, σ)
    # generate new proposal
    x_proposal = rand(Normal(x_current, σ))
    u = rand()
    ρ = log(target_density(x_proposal)) - log(target_density(x_current)) # transition log-probability
    if log(u) < min(ρ, 1)
        y = x_proposal
    else
        y = x_current
    end
    return y, log(target_density(y))
end
```

## Julia Implementation

```{julia}
#| echo: true
#| label: mcmc-algorithm

function mh_algorithm(n_iter, σ, x₀)
    # initialize storage
    samples = zeros(n_iter) 
    log_target = zeros(n_iter)
    samples[1] = x₀ # start algorithm
    log_target[1] = log(target_density(x₀))
    accept_count = 0
    for i = 2:length(samples) # iterate
        samples[i], log_target[i] = mh_transition(samples[i-1], σ)
        if samples[i] != samples[i-1]
            accept_count += 1
        end
    end
    accept_rate = accept_count / n_iter # compute acceptance rate
    return samples, log_target, accept_rate
end
```

## Linear Regression Example

:::: {.columns}
::: {.column width=50%}
$$
\begin{gather}
y = 5 + 2x + \varepsilon \\
\varepsilon \sim \text{Normal}(0, 3)
\end{gather}
$$
:::
::: {.column width=50%}
```{julia}
#| echo: true
#| label: fig-mcmc-regression
#| fig-cap: Regression data plot
#| code-fold: true

# create trend for data
x = rand(Uniform(0, 20), 20)
y = 5 .+ 2 * x
# sample and add noise
ε = rand(Normal(0, 3), 20)
y .+= ε

p = scatter(x, y, label="Data", xlabel=L"$x$", ylabel=L"$y$", markershape=:o, markersize=10, tickfontsize=16, guidefontsize=18, legendfontsize=16, bottom_margin=10mm, left_margin=5mm, right_margin=5mm) 
plot!(p, size=(600, 550))
```

:::
::::

## Model Specification

$$
\begin{gather}
y = a + bx + \varepsilon \\
\varepsilon \sim \text{Normal}(0, \sigma).
\end{gather}
$$

This makes the likelihood:
$$
y \sim \text{Normal}(a+bx, \sigma).
$$

## Prior Selection

:::: {.columns}
::: {.column width=50%}
$$
\begin{gather}
a \sim \text{Normal(0, 2)} \\
b \sim \text{Normal(0, 2)} \\
\sigma \sim \text{Half-Normal}(0, 1)
\end{gather}
$$
:::
::: {.column width=50%}
```{julia}
#| echo: true
#| code-fold: true
#| label: fig-regression-prior
#| fig-cap: Prior predictive plot for regression example.

# generate data for samples
function gen_data(a, b, σ)
    x = collect(0:20)
    y = a .+ b * x
    # sample and add noise
    ε = rand(Normal(0, σ), length(x))
    y .+= ε
    return y
end

# sample and plot
n_samples = 1000
a = rand(Normal(0, 2), n_samples)
b = rand(Normal(0, 2), n_samples)
σ = rand(truncated(Normal(0, 1), lower=0), 1000)
y_prior = [gen_data(a[i], b[i], σ[i]) for i in 1:n_samples]
# convert y to a Matrix by vcatting each vector
y_prior = mapreduce(permutedims, vcat, y_prior) 
plt_prior_1 = plot(; ylabel=L"$y$", xlabel=L"$x$",
    tickfontsize=16, legendfontsize=16, guidefontsize=18, bottom_margin=5mm, left_margin=5mm, legend=false)
for x ∈ [0, 5, 10, 15, 20]
    boxplot!(plt_prior_1, [x], y_prior[:, x+1], color=:blue)
end
plot!(plt_prior_1, size=(600, 550))
plt_prior_1
```
:::
::::

## Proposal Distribution and Initial Value

To illustrate how the M-H algorithm works, let's use a proposal $$\mathcal{N}(x_t, 0.01I_3).$$

And let's start at $$x_0 = \begin{pmatrix}1 \\ 1 \\ 1\end{pmatrix}$$.

## First Proposal

```{julia}
#| echo: false
#| label: mcmc-iteration-1
#| output: false

function regression_posterior(p, x, y)
    # priors
    lp = logpdf(Normal(0, 2), p[1]) + logpdf(Normal(0, 2), p[2]) + logpdf(truncated(Normal(0, 1), lower=0), p[3])
    if !isinf(lp)
        y_sim = p[1] .+ p[2] .* x
        ll = sum(logpdf.(Normal(0, p[3]), y_sim - y))
    else 
        ll = 0
    end
    return ll + lp
end

function mh_reg_transition(p_current, x, y)
    # generate new proposal
    p_proposal = rand(MvNormal(p_current, 0.01I))
    u = rand()
    ρ = regression_posterior(p_proposal, x, y) - regression_posterior(p_current, x, y) # transition log-probability
    if log(u) < min(ρ, 1)
        p_new = p_proposal
    else
        p_new = p_current
    end
    return p_new, regression_posterior(p_new, x, y)
end

function mh_algorithm(n_iter, p₀, x, y)
    # initialize storage
    samples = zeros(n_iter, length(p₀)) 
    log_target = zeros(n_iter)
    samples[1, :] = p₀ # start algorithm
    log_target[1] = regression_posterior(p₀, x, y)
    accept_count = 0
    for i = 2:n_iter # iterate
        samples[i, :], log_target[i] = mh_reg_transition(samples[i-1, :], x, y)
        if samples[i, :] != samples[i-1, :]
            accept_count += 1
        end
    end
    accept_rate = accept_count / n_iter # compute acceptance rate
    return samples, log_target, accept_rate
end
```

:::: {.columns}
::: {.column width=50%}
**Current**:

$$X_0 = \begin{pmatrix}1 \\ 1 \\ 1\end{pmatrix}$$

$$\text{log-posterior} = -2851$$
:::

::: {.column width=50%}
**Iteration**:

$$y = \begin{pmatrix}0.94 \\ 1.07 \\ 0.82\end{pmatrix}$$

$$\text{log-posterior} = -3433$$
:::
::::

$$\rho \approx 0 \Rightarrow X_1 = X_0$$

## Another Proposal

:::: {.columns}
::: {.column width=50%}
**Current**:

$$X_1 = \begin{pmatrix}1 \\ 1 \\ 1\end{pmatrix}$$

$$\text{log-posterior} = -2851$$
:::

::: {.column width=50%}
**Iteration**:

$$y = \begin{pmatrix}1.24 \\ 1.05 \\ 1.04\end{pmatrix}$$

$$\text{log-posterior} = -2165$$
:::
::::

$$\rho =1 \Rightarrow X_2 = y$$

## 1,000 Iterations

```{julia}
#| echo: true
#| code-fold: true
#| label: fig-iteration-1000
#| fig-cap: First 1,000 iterations of the MCMC example

samples, lpost, α = mh_algorithm(100000, [1; 1; 1], x, y)

p = plot(samples[1:1000, :], layout=(1, 3), label="Samples", guidefontsize=18, tickfontsize=16, legendfontsize=16, bottom_margin=15mm, ylabel="Value", xlabel="Iteration", left_margin=10mm)
hline!(p, [5 2 3], color=:red, linestyle=:dash, label="True Value")
plot!(p, size=(1300, 400))
```

## 100,000 Iterations

```{julia}
#| echo: true
#| code-fold: true
#| label: fig-iteration-all
#| fig-cap: 100,000 iterations of the MCMC example
#| fig-format: png

p = plot(samples, layout=(1, 3), label="Samples", guidefontsize=18, tickfontsize=16, legendfontsize=16, bottom_margin=15mm, xlabel="Iteration", left_margin=10mm, xticks=0:50000:100000, right_margin=15mm, ylabel = [L"$a$" L"$b$" L"$\sigma$"], legend=[:false :bottomright :false])
hline!(p, [5 2 3], color=:red, linestyle=:dash, label="True Value", linewidth=3)
plot!(p, size=(1300, 400))
```

Acceptance rate: `{julia} α`

## Marginal Distributions

```{julia}
#| echo: true
#| code-fold: true
#| label: fig-iteration-marginal
#| fig-cap: 100,000 iterations of the MCMC example
#| fig-format: png

p = histogram(samples[10001:end, :], layout=(1, 3), label=false, guidefontsize=18, tickfontsize=16, legendfontsize=14, bottom_margin=15mm, ylabel="Count", left_margin=10mm, xlabel = [L"$a$" L"$b$" L"$\sigma$"], legend=[:false :false :topright], color=:lightblue)
vline!(p, [5 2 3], color=:red, linestyle=:dash, label="True Value", linewidth=3)
vline!(p, mapslices(mean, samples[10001:end, :], dims=1), color=:purple, linestyle=:dash, label="Posterior Mean", linewidth=3)
plot!(p, size=(1300, 450))
```

# Considerations for Implementation

## Proposal Distribution Example

```{julia}
#| echo: true
#| code-fold: true
#| label: fig-mcmc-base
#| fig-cap: "Example target density for Metropolis-Hastings"

# target density: modified Normal(0, 1) PDF
function target_distribution(x) 
    return sin(x)^2 * sin(2x)^2 * pdf(Normal(0, 1), x)
end

# compute normalizing constant for normalization
marg_dens, error = quadgk(x -> target_distribution(x), -Inf, Inf)
# plot target density
x = -π:0.01:π
p_base = plot(x, target_distribution.(x) ./ marg_dens, linewidth=3, label="Target Density", tickfontsize=16, legendfontsize=16, guidefontsize=18, bottom_margin=5mm, left_margin=5mm)
plot!(xlabel=L"x", ylabel="Density")
# pick current value
x_current = 0.5
vline!([x_current], color=:black, linewidth=2, label=L"$x_t$")
```

## Proposal Distribution Examples

```{julia}
#| echo: true
#| code-fold: true
#| label: fig-mcmc-proposals
#| fig-cap: "Example target density for Metropolis-Hastings"
#| layout-ncol: 2

# plot proposal distributions
p1 = plot!(deepcopy(p_base), x, pdf.(Normal(x_current, 0.1), x) ./ 10, color=:purple, label="Scaled Narrow Proposal", linewidth=2, linestyle=:dash)
p2 = plot!(deepcopy(p_base), x, pdf.(Normal(x_current, 0.5), x) ./ 2, color=:red, label="Scaled Wide Proposal", linewidth=2, linestyle=:dash)
plot!(p1, size=(600, 500))
plot!(p2, size=(600, 500))
display(p1)
display(p2)
```

## Sampling Efficiency

Two common measures of sampling efficiency:

- **Acceptance Rate**: Rate at which proposals are accepted
  - "Optimally" 30-45% (depending on number of parameters)
- **Effective Sample Size (ESS)**: Accounts for autocorrelation $\rho_t$ across samples
  $$N_\text{eff} = \frac{N}{1+2\sum_{t=1}^\infty \rho_t}$$


## Sampling Efficiency Example

::: {.center}
![MCMC Sampling for Various Proposals](figures/mcmc-trace.svg)
:::

## Autocorrelation of Chains

::: {.center}
![MCMC Sampling for Various Proposals](figures/mh-acplot.svg){width=80%}
:::

## ESS by Proposal Variance for Example

::: {.center}
![MCMC Sampling for Various Proposals](figures/mcmc-ess.svg){width=60%}
:::

# Key Points, Upcoming Schedule, and References

## Key Points (Metropolis-Hastings)

- Construct ergodic and reversible Markov chains with posterior as stationary distribution.
- Metropolis-Hastings: conceptually simple algorithm, but implementation plays a major role.
- Proposal distribution plays a large role in acceptance rate and effective sample size.

## Next Classes

**Wednesday**: MCMC Examples

**Monday**: MCMC Lab (No exercises these weeks)

**Next Wednesday**: Literature Presentations (email slides by 9pm Tuesday night).

## Assessments

- **Homework 3**: Due 3/22


## References