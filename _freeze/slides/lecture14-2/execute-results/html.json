{
  "hash": "6714dc1a45e5fc3f8fee847db3e162f5",
  "result": {
    "engine": "julia",
    "markdown": "---\ntitle: \"Emulation Wrap-Up and Class Review\"\nsubtitle: \"Lecture 22\"\nauthor: \"Vivek Srikrishnan\"\ncourse: \"BEE 4850\"\ninstitution: \"Cornell University\"\ndate: \"May 1, 2024\"\nformat:\n    revealjs:\n        slide-number: c/t\n        show-slide-number: all\n        center-title-slide: true\n        width: 1280\n        height: 720\n        transition: none\n        toc: true\n        toc-depth: 1\n        toc-title: \"Overview\"\n        history: false\n        link-external-newwindow: true\n        theme: ../sass/slides.scss\n        template-partials:\n            - title-slide.html\n        menu:\n            numbers: true\n        html-math-method: \n            method: mathjax\n            url: \"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js\"\n        include-in-header: mathjax-config.html\n        date-format: long\n        email-obfuscation: javascript\n        chalkboard:\n            theme: whiteboard\n            buttons: true\n        touch: false\n        controls: true\nengine: julia\njulia:\n    exeflags: [\"+1.10.4\"]          \nexecute:\n    freeze: auto\n---\n\n\n# Review of Last Class\n\n## Benefits of Model Simplicity\n\n:::: {.columns}\n::: {.column width=50%}\n- More thorough representation of uncertainties\n- Can focus on \"important\" characteristics for problem at hand\n- Potential increase in generalizability\n:::\n::: {.column width=50%}\n![Computational Complexity](figures/simplicity-calibration.png)\n\n::: {.caption}\nSource: @Helgeson2021-ok\n:::\n:::\n::::\n\n## Downsides of Model Simplicity\n\n- Potential loss of salience\n- May miss important dynamics (creating bias)\n- Parameter/dynamical compensation can result in loss of interpretability\n\n## Simplicity Tradeoffs\n\nSimple models can be epistemically and practically valuable.\n\n**But**:\n\nNeed to carefully select which processes/parameters are included in the simplified representation, and at what resolution.\n\n## Approximating Complex Models\n\n**Challenge**: How do we simplify complex models to keep key dynamics but reduce computational expense?\n\n::: {.fragment .fade-in}\nApproximate (or **emulate**) the model response surface.\n\n1. Evaluate original model at an ensemble of points (design of experiment)\n2. Calibrate emulator against those points.\n3. Use emulator for UQ with MCMC or other methods.\n:::\n\n## Design of Experiments\n\nImportant to strike a balance betwee:\n\n- Computational expense for model evaluation\n- Dense/expansive enough sample for training\n\n# Emulation Methods\n\n## Overview of Methods\n\nAny \"simple\", fast to evaluate model structure can be used for emulation:\n\n::: {.incremental}\n- Gaussian processes;\n- Artificial neural networks (or other ML methods);\n- Polynomial chaos expansions;\n- Radial basis functions;\n- Reduced-form models (think SLR semi-empirical model)\n:::\n\n## How To Choose An Emulation Method?\n\n- Dimensionality of problem\n- Interpretability vs. response surface complexity\n- Needed number of training evaluations\n- Hyperparameter tuning\n\n## Selecting Parameters For Simplification\n\nSimplification often involves down-selecting parameters of interest.\n\nThis could be based on:\n\n1. Scientific relevance;\n2. Factor importance\n\n## Factor Prioritization\n\n::: {.center}\n![Modes of Sensitivity Analysis](https://uc-ebook.org/docs/html/_images/figure3_2_factor_mapping.png){width=45%}\n\n::: {.caption}\nSource: @Reed2022-fm\n:::\n:::\n\n## How to Rank Factors?\n\n**Sensitivity Analysis**:\n\n- All-At-Once vs. One-at-a-Time\n- Local vs. Global\n\n::: {.fragment .fade-in}\nGood overview with some notebooks: @Reed2022-fm\n:::\n\n## Types of Sensitivity Analysis\n\n::: {.center}\n![Types of Sensitivity Analysis](https://uc-ebook.org/docs/html/_images/figure3_1_global_versus_local.png){width=75%}\n\n::: {.caption}\nSource: @Reed2022-fm\n:::\n:::\n\n## Design of Experiments\n\n::: {.center}\n![Design of Experiments](https://uc-ebook.org/docs/html/_images/figure3_3_alternative_designs.png){width=60%}\n\n::: {.caption}\nSource: @Reed2022-fm\n:::\n:::\n\n# Class Review\n\n## Why Does Data Analysis Matter?\n\n- Scientific insight;\n- Decision-making;\n- Understanding uncertainty\n\n## The Ideal\n\n::: {.center}\n![XKCD #2400](https://imgs.xkcd.com/comics/statistics.png){width=30%}\n\n::: {.caption}\nSource: [XKCD 2400](https://xkcd.com/2400/)\n:::\n:::\n\n## Modes of Data Analysis\n\n::: {.center}\n![](figures/data_settings.png)\n:::\n\n## What Did We Do?\n\n1. Probability Models for Data\n2. Bayesian and Frequentist Statistics\n3. Monte Carlo/Bootstrap Simulation\n4. Assessing Model-Data Fit and Hypothesis Testing\n\n## What Are Some  Next Directions?\n\n- More specific models/statistical methods (time series, spatial statistics, hidden Markov models, model-based clustering, etc)\n- Machine learning and clustering\n- Dimension reduction (principal components, singular value decomposition, etc)\n\n# Key Takeaways and Upcoming Schedule\n\n## Upcoming Schedule\n\n**Friday**: HW4 due\n\n**Next Monday**: Project Presentations, email slides by Saturday.\n\n# References\n\n## References\n\n",
    "supporting": [
      "lecture14-2_files"
    ],
    "filters": [],
    "includes": {}
  }
}